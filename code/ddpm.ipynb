{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be implementing the Denoising Diffusion Probabilistic Model from the paper with the same name by Ho et al. (2020)\n",
    "Generation will be on MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from https://github.com/zoubohao/DenoisingDiffusionProbabilityModel-ddpm-/blob/main/Diffusion/Model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, T, d_model, dim):\n",
    "        super().__init__()\n",
    "        emb = torch.arange(0, d_model, step=2) / d_model * np.log(10000)\n",
    "        emb = torch.exp(-emb)\n",
    "        pos = torch.arange(T).float()\n",
    "        emb = pos[:, None] * emb[None, :]\n",
    "        emb = torch.stack([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "        emb = emb.view(T, d_model)\n",
    "\n",
    "        self.timembedding = nn.Sequential(\n",
    "            nn.Embedding.from_pretrained(emb),\n",
    "            nn.Linear(d_model, dim),\n",
    "            Swish(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                init.xavier_uniform_(module.weight)\n",
    "                init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, t):\n",
    "        emb = self.timembedding(t)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.main = nn.Conv2d(in_ch, in_ch, 3, stride=2, padding=1)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.main.weight)\n",
    "        init.zeros_(self.main.bias)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.main = nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.main.weight)\n",
    "        init.zeros_(self.main.bias)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        _, _, H, W = x.shape\n",
    "        x = F.interpolate(\n",
    "            x, scale_factor=2, mode='nearest')\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.group_norm = nn.GroupNorm(32, in_ch)\n",
    "        self.proj_q = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj_k = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj_v = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in [self.proj_q, self.proj_k, self.proj_v, self.proj]:\n",
    "            init.xavier_uniform_(module.weight)\n",
    "            init.zeros_(module.bias)\n",
    "        init.xavier_uniform_(self.proj.weight, gain=1e-5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        h = self.group_norm(x)\n",
    "        q = self.proj_q(h)\n",
    "        k = self.proj_k(h)\n",
    "        v = self.proj_v(h)\n",
    "\n",
    "        q = q.permute(0, 2, 3, 1).view(B, H * W, C)\n",
    "        k = k.view(B, C, H * W)\n",
    "        w = torch.bmm(q, k) * (int(C) ** (-0.5))\n",
    "        assert list(w.shape) == [B, H * W, H * W]\n",
    "        w = F.softmax(w, dim=-1)\n",
    "\n",
    "        v = v.permute(0, 2, 3, 1).view(B, H * W, C)\n",
    "        h = torch.bmm(w, v)\n",
    "        assert list(h.shape) == [B, H * W, C]\n",
    "        h = h.view(B, H, W, C).permute(0, 3, 1, 2)\n",
    "        h = self.proj(h)\n",
    "\n",
    "        return x + h\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, tdim, dropout, attn=False):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.GroupNorm(32, in_ch),\n",
    "            Swish(),\n",
    "            nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1),\n",
    "        )\n",
    "        self.temb_proj = nn.Sequential(\n",
    "            Swish(),\n",
    "            nn.Linear(tdim, out_ch),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.GroupNorm(32, out_ch),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1),\n",
    "        )\n",
    "        if in_ch != out_ch:\n",
    "            self.shortcut = nn.Conv2d(in_ch, out_ch, 1, stride=1, padding=0)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "        if attn:\n",
    "            self.attn = AttnBlock(out_ch)\n",
    "        else:\n",
    "            self.attn = nn.Identity()\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "                init.xavier_uniform_(module.weight)\n",
    "                init.zeros_(module.bias)\n",
    "        init.xavier_uniform_(self.block2[-1].weight, gain=1e-5)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        h = self.block1(x)\n",
    "        h += self.temb_proj(temb)[:, :, None, None]\n",
    "        h = self.block2(h)\n",
    "\n",
    "        h = h + self.shortcut(x)\n",
    "        h = self.attn(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, T, ch, ch_mult, attn, num_res_blocks, dropout):\n",
    "        super().__init__()\n",
    "        assert all([i < len(ch_mult) for i in attn]), 'attn index out of bound'\n",
    "        tdim = ch * 4\n",
    "        self.time_embedding = TimeEmbedding(T, ch, tdim)\n",
    "\n",
    "        self.head = nn.Conv2d(3, ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.downblocks = nn.ModuleList()\n",
    "        chs = [ch]  # record output channel when dowmsample for upsample\n",
    "        now_ch = ch\n",
    "        for i, mult in enumerate(ch_mult):\n",
    "            out_ch = ch * mult\n",
    "            for _ in range(num_res_blocks):\n",
    "                self.downblocks.append(ResBlock(\n",
    "                    in_ch=now_ch, out_ch=out_ch, tdim=tdim,\n",
    "                    dropout=dropout, attn=(i in attn)))\n",
    "                now_ch = out_ch\n",
    "                chs.append(now_ch)\n",
    "            if i != len(ch_mult) - 1:\n",
    "                self.downblocks.append(DownSample(now_ch))\n",
    "                chs.append(now_ch)\n",
    "\n",
    "        self.middleblocks = nn.ModuleList([\n",
    "            ResBlock(now_ch, now_ch, tdim, dropout, attn=True),\n",
    "            ResBlock(now_ch, now_ch, tdim, dropout, attn=False),\n",
    "        ])\n",
    "\n",
    "        self.upblocks = nn.ModuleList()\n",
    "        for i, mult in reversed(list(enumerate(ch_mult))):\n",
    "            out_ch = ch * mult\n",
    "            for _ in range(num_res_blocks + 1):\n",
    "                self.upblocks.append(ResBlock(\n",
    "                    in_ch=chs.pop() + now_ch, out_ch=out_ch, tdim=tdim,\n",
    "                    dropout=dropout, attn=(i in attn)))\n",
    "                now_ch = out_ch\n",
    "            if i != 0:\n",
    "                self.upblocks.append(UpSample(now_ch))\n",
    "        assert len(chs) == 0\n",
    "\n",
    "        self.tail = nn.Sequential(\n",
    "            nn.GroupNorm(32, now_ch),\n",
    "            Swish(),\n",
    "            nn.Conv2d(now_ch, 3, 3, stride=1, padding=1)\n",
    "        )\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.head.weight)\n",
    "        init.zeros_(self.head.bias)\n",
    "        init.xavier_uniform_(self.tail[-1].weight, gain=1e-5)\n",
    "        init.zeros_(self.tail[-1].bias)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Timestep embedding\n",
    "        temb = self.time_embedding(t)\n",
    "        # Downsampling\n",
    "        h = self.head(x)\n",
    "        hs = [h]\n",
    "        for layer in self.downblocks:\n",
    "            h = layer(h, temb)\n",
    "            hs.append(h)\n",
    "        # Middle\n",
    "        for layer in self.middleblocks:\n",
    "            h = layer(h, temb)\n",
    "        # Upsampling\n",
    "        for layer in self.upblocks:\n",
    "            if isinstance(layer, ResBlock):\n",
    "                h = torch.cat([h, hs.pop()], dim=1)\n",
    "            h = layer(h, temb)\n",
    "        h = self.tail(h)\n",
    "\n",
    "        assert len(hs) == 0\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_reshape(v, t, x_shape):\n",
    "    \"\"\"\n",
    "    :param v: tensor of parameters (such as beta)\n",
    "    :param t: tensor of indices, for each element in batch has a corresponding index\n",
    "    :param x_shape: shape of the output tensor (to easily find x_t)\n",
    "    \"\"\"\n",
    "    out = torch.gather(v, index=t, dim=0).float().to(device)\n",
    "    return out.view([t.shape[0]] + [1] * (len(x_shape) - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionLoss(nn.Module):\n",
    "    def __init__(self, T, model, beta_1, beta_T):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.model = model\n",
    "        self.register_buffer('beta', torch.linspace(beta_1, beta_T, T))\n",
    "        a = 1 - self.beta\n",
    "        alpha = torch.cumprod(a, 0)\n",
    "        self.register_buffer('sqrt_alpha', alpha.sqrt())\n",
    "        self.register_buffer('sqrt_1m_alpha', (1 - alpha))\n",
    "\n",
    "    def forward(self, train_x):\n",
    "        B, C, H, W = train_x.shape\n",
    "        t = torch.randint(self.T, (B, ))  # time index is uniform (int)\n",
    "        noise = torch.randn_like(train_x)  # epsilon\n",
    "        x_t = gather_reshape(self.sqrt_alpha, t, train_x.shape) * train_x + gather_reshape(self.sqrt_1m_alpha, t, train_x.shape) * noise  # according to equation\n",
    "        loss = F.mse_loss(self.model(x_t, t), noise)\n",
    "        return loss\n",
    "    \n",
    "\n",
    "class DiffusionSampler(nn.Module):\n",
    "    def __init__(self, T, model, beta_1, beta_T):\n",
    "        super().__init__()\n",
    "        self.T = T\n",
    "        self.model = model\n",
    "        self.register_buffer('beta', torch.linspace(beta_1, beta_T, T))\n",
    "        self.register_buffer('variance', torch.cat([torch.tensor([0]), self.beta[1:]]))\n",
    "        a = 1 - self.beta\n",
    "        alpha = torch.cumprod(a, 0)\n",
    "        self.register_buffer('coeff_prev', 1 / alpha.sqrt())\n",
    "        self.register_buffer('coeff_noise', self.coeff_prev * (1 - self.beta) / (1 - alpha).sqrt())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for t in reversed(range(self.T)):\n",
    "            if t == 0:\n",
    "                noise = 0\n",
    "            else:\n",
    "                noise = torch.randn_like(x)\n",
    "            t = x.new_ones(x.shape[0]) * t\n",
    "            mean = gather_reshape(self.coeff_prev, t, x.shape) * x - gather_reshape(self.coeff_noise, t, x.shape) * self.model(x, t)\n",
    "            var = gather_reshape(self.variance, t, x.shape)\n",
    "            x = mean + torch.sqrt(var) * noise\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(T=1000, ch=64, ch_mult=(1, 2, 2, 4), attn=(0, 1, 2, 3), num_res_blocks=2, dropout=0.1).to(device)\n",
    "loss_fn = DiffusionLoss(T=1000, model=model, beta_1=0.0001, beta_T=0.02)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(100)):\n",
    "    for x, _ in train_loader:\n",
    "        x = x.to(device)\n",
    "        loss = loss_fn(x)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "    print(f'Epoch {epoch} Loss {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 3, 32, 32)\n",
    "t = torch.randint(2, (2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(2, 64, [2, 2, 2, 2], [1, 3], 2, 0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10951299"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = DiffusionSampler(2, model, 0.01, 0.1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-5.1063e-01, -1.1846e+00,  1.9892e+00,  ..., -3.9252e-02,\n",
       "           -1.0488e+00, -1.2237e+00],\n",
       "          [ 1.4269e+00,  1.0801e+00,  8.1339e-01,  ..., -1.0344e+00,\n",
       "           -1.6252e-01,  2.5414e+00],\n",
       "          [-2.4462e-01,  2.0766e+00, -1.3673e-02,  ..., -6.4854e-01,\n",
       "           -2.0041e-01, -1.1301e+00],\n",
       "          ...,\n",
       "          [-8.7303e-01, -1.9073e-01, -2.4993e-01,  ...,  3.0115e-01,\n",
       "            5.7494e-01,  2.6118e-01],\n",
       "          [ 4.3245e-01, -2.6581e-01,  3.0842e-01,  ..., -6.8901e-01,\n",
       "            7.9575e-01, -3.0081e-01],\n",
       "          [ 8.3180e-01,  1.4765e+00, -1.0293e+00,  ..., -9.5463e-01,\n",
       "           -1.3505e+00,  1.8644e+00]],\n",
       "\n",
       "         [[ 2.7015e+00, -1.1578e+00,  1.8737e-01,  ...,  5.5893e-01,\n",
       "            2.7249e+00, -2.5220e+00],\n",
       "          [-1.3063e+00, -1.4486e+00, -1.1028e+00,  ...,  7.4785e-01,\n",
       "            2.0098e+00,  6.4185e-01],\n",
       "          [-7.8450e-01, -2.3460e+00, -8.4807e-01,  ...,  1.4677e-01,\n",
       "           -9.7963e-03, -1.0759e+00],\n",
       "          ...,\n",
       "          [ 1.1597e+00, -2.9677e+00, -1.2213e+00,  ...,  1.2928e+00,\n",
       "           -4.1829e-01, -1.1839e+00],\n",
       "          [ 1.0390e+00,  1.9276e+00, -3.2544e-01,  ...,  1.3219e+00,\n",
       "            1.1608e+00,  6.3967e-01],\n",
       "          [ 1.2908e+00, -9.4367e-02, -4.6102e-01,  ..., -2.4079e-01,\n",
       "            1.4012e+00, -1.1669e-01]],\n",
       "\n",
       "         [[ 1.2037e+00,  4.7193e-01,  2.0380e+00,  ..., -1.1646e-01,\n",
       "           -2.4377e-01, -1.3819e-01],\n",
       "          [ 1.7483e+00, -4.2500e-01, -2.3605e-02,  ..., -1.2653e-01,\n",
       "            6.8868e-02,  1.2988e+00],\n",
       "          [ 3.3043e-01, -4.0028e-01, -7.0733e-01,  ...,  2.0193e-01,\n",
       "           -1.4461e+00, -4.4250e-02],\n",
       "          ...,\n",
       "          [ 4.9480e-01,  6.5290e-01,  6.6558e-01,  ...,  7.2352e-01,\n",
       "            4.0300e-04,  3.8519e-01],\n",
       "          [ 1.1628e+00,  1.1820e+00, -4.4144e-01,  ..., -1.6912e+00,\n",
       "            9.4876e-01,  8.8406e-01],\n",
       "          [-1.2863e+00, -1.4282e+00,  1.5040e+00,  ..., -1.3488e+00,\n",
       "            1.2323e+00,  5.2883e-01]]],\n",
       "\n",
       "\n",
       "        [[[-2.7889e-01, -1.2688e+00,  2.8286e-01,  ..., -4.9678e-01,\n",
       "            2.3306e+00, -1.0810e+00],\n",
       "          [ 5.5916e-01,  1.7874e+00,  4.7495e-01,  ...,  6.1752e-01,\n",
       "           -2.5540e+00, -1.9481e-01],\n",
       "          [-9.0763e-01,  1.7822e+00, -2.3550e-01,  ..., -1.4655e+00,\n",
       "            3.7867e-01,  1.8192e-01],\n",
       "          ...,\n",
       "          [ 3.5478e-01, -1.9366e-02, -1.0806e+00,  ..., -2.6328e+00,\n",
       "           -7.3244e-01,  2.2026e+00],\n",
       "          [ 2.0803e+00,  1.3052e+00,  9.1602e-01,  ..., -1.0882e+00,\n",
       "           -1.1519e+00,  5.8647e-01],\n",
       "          [ 4.2086e-01, -5.5783e-01,  4.7001e-01,  ..., -1.7138e+00,\n",
       "            8.9021e-01,  2.3800e-01]],\n",
       "\n",
       "         [[-1.7157e+00,  1.9120e+00, -2.4906e+00,  ..., -8.2163e-01,\n",
       "           -1.7767e+00,  1.0847e+00],\n",
       "          [-4.1692e-01, -1.8829e+00, -8.2721e-01,  ..., -1.4637e-01,\n",
       "           -1.4303e+00,  1.3344e+00],\n",
       "          [ 1.5109e+00, -1.4679e-02,  9.0128e-01,  ..., -2.6423e-01,\n",
       "           -1.8973e+00,  3.7820e-01],\n",
       "          ...,\n",
       "          [-5.7738e-04, -1.1393e+00,  1.4452e+00,  ..., -2.3903e+00,\n",
       "           -7.0439e-01,  2.1368e-01],\n",
       "          [-2.3644e-01,  1.0964e+00, -1.7317e+00,  ..., -9.0396e-01,\n",
       "            2.0771e-02, -2.6404e+00],\n",
       "          [-1.7354e+00, -4.1981e-01, -8.7430e-01,  ..., -3.7022e-01,\n",
       "            1.9850e+00,  1.1064e+00]],\n",
       "\n",
       "         [[ 3.4687e-01,  3.5775e-01,  1.5141e+00,  ..., -7.7340e-01,\n",
       "            9.0997e-01,  1.7244e+00],\n",
       "          [ 5.8597e-01,  1.8437e-01,  5.7902e-01,  ..., -1.8648e+00,\n",
       "           -7.1686e-01, -2.3759e+00],\n",
       "          [ 3.5870e-02, -4.8467e-01,  2.3834e+00,  ..., -3.9099e-01,\n",
       "            2.7637e-01,  5.6293e-01],\n",
       "          ...,\n",
       "          [-1.2648e-01,  9.0310e-01,  1.0290e-01,  ..., -1.7900e+00,\n",
       "           -1.7635e+00, -6.4820e-01],\n",
       "          [-3.1061e-01, -8.8003e-02,  4.6970e-02,  ..., -1.1645e+00,\n",
       "            2.2202e+00, -9.3884e-01],\n",
       "          [-1.8340e+00,  5.1289e-01,  2.7588e+00,  ...,  6.6441e-01,\n",
       "           -2.1111e+00, -1.0884e-01]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0528)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= torch.randn(2, 3, 32, 32)\n",
    "b = torch.randn(2, 3, 32, 32)\n",
    "\n",
    "F.mse_loss(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
