{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Based Generative Models Using Stochastic Differential Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incorporating the same architecture in DDPM using the VP SDE framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import numpy as np\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class TimeEmbedding(nn.Module):\n",
    "    def __init__(self, T, d_model, dim):\n",
    "        super().__init__()\n",
    "        emb = torch.arange(0, d_model, step=2) / d_model * np.log(10000)\n",
    "        emb = torch.exp(-emb)\n",
    "        pos = torch.arange(T).float()\n",
    "        emb = pos[:, None] * emb[None, :]\n",
    "        emb = torch.stack([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "        emb = emb.view(T, d_model)\n",
    "\n",
    "        self.timembedding = nn.Sequential(\n",
    "            nn.Embedding.from_pretrained(emb),\n",
    "            nn.Linear(d_model, dim),\n",
    "            Swish(),\n",
    "            nn.Linear(dim, dim),\n",
    "        )\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                init.xavier_uniform_(module.weight)\n",
    "                init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, t):\n",
    "        emb = self.timembedding(t)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.main = nn.Conv2d(in_ch, in_ch, 3, stride=2, padding=1)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.main.weight)\n",
    "        init.zeros_(self.main.bias)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.main = nn.Conv2d(in_ch, in_ch, 3, stride=1, padding=1)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.main.weight)\n",
    "        init.zeros_(self.main.bias)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        _, _, H, W = x.shape\n",
    "        x = F.interpolate(\n",
    "            x, scale_factor=2, mode='nearest')\n",
    "        x = self.main(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, in_ch):\n",
    "        super().__init__()\n",
    "        self.group_norm = nn.GroupNorm(32, in_ch)\n",
    "        self.proj_q = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj_k = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj_v = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.proj = nn.Conv2d(in_ch, in_ch, 1, stride=1, padding=0)\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in [self.proj_q, self.proj_k, self.proj_v, self.proj]:\n",
    "            init.xavier_uniform_(module.weight)\n",
    "            init.zeros_(module.bias)\n",
    "        init.xavier_uniform_(self.proj.weight, gain=1e-5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        h = self.group_norm(x)\n",
    "        q = self.proj_q(h)\n",
    "        k = self.proj_k(h)\n",
    "        v = self.proj_v(h)\n",
    "\n",
    "        q = q.permute(0, 2, 3, 1).view(B, H * W, C)\n",
    "        k = k.view(B, C, H * W)\n",
    "        w = torch.bmm(q, k) * (int(C) ** (-0.5))\n",
    "        assert list(w.shape) == [B, H * W, H * W]\n",
    "        w = F.softmax(w, dim=-1)\n",
    "\n",
    "        v = v.permute(0, 2, 3, 1).view(B, H * W, C)\n",
    "        h = torch.bmm(w, v)\n",
    "        assert list(h.shape) == [B, H * W, C]\n",
    "        h = h.view(B, H, W, C).permute(0, 3, 1, 2)\n",
    "        h = self.proj(h)\n",
    "\n",
    "        return x + h\n",
    "\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, tdim, dropout, attn=False):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.GroupNorm(32, in_ch),\n",
    "            Swish(),\n",
    "            nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1),\n",
    "        )\n",
    "        self.temb_proj = nn.Sequential(\n",
    "            Swish(),\n",
    "            nn.Linear(tdim, out_ch),\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.GroupNorm(32, out_ch),\n",
    "            Swish(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, stride=1, padding=1),\n",
    "        )\n",
    "        if in_ch != out_ch:\n",
    "            self.shortcut = nn.Conv2d(in_ch, out_ch, 1, stride=1, padding=0)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "        if attn:\n",
    "            self.attn = AttnBlock(out_ch)\n",
    "        else:\n",
    "            self.attn = nn.Identity()\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "                init.xavier_uniform_(module.weight)\n",
    "                init.zeros_(module.bias)\n",
    "        init.xavier_uniform_(self.block2[-1].weight, gain=1e-5)\n",
    "\n",
    "    def forward(self, x, temb):\n",
    "        h = self.block1(x)\n",
    "        h += self.temb_proj(temb)[:, :, None, None]\n",
    "        h = self.block2(h)\n",
    "\n",
    "        h = h + self.shortcut(x)\n",
    "        h = self.attn(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, T, ch, ch_mult, attn, num_res_blocks, dropout):\n",
    "        super().__init__()\n",
    "        assert all([i < len(ch_mult) for i in attn]), 'attn index out of bound'\n",
    "        tdim = ch * 4\n",
    "        self.time_embedding = TimeEmbedding(T, ch, tdim)\n",
    "\n",
    "        self.head = nn.Conv2d(1, ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.downblocks = nn.ModuleList()\n",
    "        chs = [ch]  # record output channel when dowmsample for upsample\n",
    "        now_ch = ch\n",
    "        for i, mult in enumerate(ch_mult):\n",
    "            out_ch = ch * mult\n",
    "            for _ in range(num_res_blocks):\n",
    "                self.downblocks.append(ResBlock(\n",
    "                    in_ch=now_ch, out_ch=out_ch, tdim=tdim,\n",
    "                    dropout=dropout, attn=(i in attn)))\n",
    "                now_ch = out_ch\n",
    "                chs.append(now_ch)\n",
    "            if i != len(ch_mult) - 1:\n",
    "                self.downblocks.append(DownSample(now_ch))\n",
    "                chs.append(now_ch)\n",
    "\n",
    "        self.middleblocks = nn.ModuleList([\n",
    "            ResBlock(now_ch, now_ch, tdim, dropout, attn=True),\n",
    "            ResBlock(now_ch, now_ch, tdim, dropout, attn=False),\n",
    "        ])\n",
    "\n",
    "        self.upblocks = nn.ModuleList()\n",
    "        for i, mult in reversed(list(enumerate(ch_mult))):\n",
    "            out_ch = ch * mult\n",
    "            for _ in range(num_res_blocks + 1):\n",
    "                self.upblocks.append(ResBlock(\n",
    "                    in_ch=chs.pop() + now_ch, out_ch=out_ch, tdim=tdim,\n",
    "                    dropout=dropout, attn=(i in attn)))\n",
    "                now_ch = out_ch\n",
    "            if i != 0:\n",
    "                self.upblocks.append(UpSample(now_ch))\n",
    "        assert len(chs) == 0\n",
    "\n",
    "        self.tail = nn.Sequential(\n",
    "            nn.GroupNorm(32, now_ch),\n",
    "            Swish(),\n",
    "            nn.Conv2d(now_ch, 1, 3, stride=1, padding=1)\n",
    "        )\n",
    "        self.initialize()\n",
    "\n",
    "    def initialize(self):\n",
    "        init.xavier_uniform_(self.head.weight)\n",
    "        init.zeros_(self.head.bias)\n",
    "        init.xavier_uniform_(self.tail[-1].weight, gain=1e-5)\n",
    "        init.zeros_(self.tail[-1].bias)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Timestep embedding\n",
    "        temb = self.time_embedding(t)\n",
    "        # Downsampling\n",
    "        h = self.head(x)\n",
    "        hs = [h]\n",
    "        for layer in self.downblocks:\n",
    "            h = layer(h, temb)\n",
    "            hs.append(h)\n",
    "        # Middle\n",
    "        for layer in self.middleblocks:\n",
    "            h = layer(h, temb)\n",
    "        # Upsampling\n",
    "        for layer in self.upblocks:\n",
    "            if isinstance(layer, ResBlock):\n",
    "                h = torch.cat([h, hs.pop()], dim=1)\n",
    "            h = layer(h, temb)\n",
    "        h = self.tail(h)\n",
    "\n",
    "        assert len(hs) == 0\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, I will be showing only the VP-SDE as it has better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VPSDE:\n",
    "    \"\"\"\n",
    "    Variance Preserving Stochastic Differential Equation.\n",
    "    From the paper, we know that this is x(t) = -1/2 beta(t) x(t) dt + sqrt(beta(t)) dW(t)\n",
    "    \"\"\"\n",
    "    def __init__(self, beta_0, beta_T, T):\n",
    "        self.beta_0 = beta_0\n",
    "        self.beta_T = beta_T\n",
    "        self.T = T\n",
    "        self.betas = torch.linspace(beta_0, beta_T, T).to(device)  # discretized\n",
    "        self.alpha = 1 - self.betas\n",
    "        self.alpha_bar = torch.cumprod(self.alpha, dim=0)\n",
    "        self.coeff_prev_diffusion = 1 / self.alpha.sqrt()\n",
    "        self.coeff_noise_diffusion = self.coeff_prev_diffusion * (1 - self.alpha) / (1 - self.alpha_bar).sqrt()\n",
    "\n",
    "    def beta(self, t):  # continuous beta\n",
    "        return self.beta_0 + (self.beta_T - self.beta_0) * t\n",
    "    \n",
    "    def sde(self, x, t):\n",
    "        \"\"\"\n",
    "        x: torch.Tensor(B, C, H, W)\n",
    "        t: torch.Tensor(B)\n",
    "        \"\"\"\n",
    "        return -0.5 * self.beta(t)[:, None, None, None] * x, torch.sqrt(self.beta(t))[:, None, None, None]\n",
    "    \n",
    "    def dist(self, x, t):\n",
    "        \"\"\"\n",
    "        x: torch.Tensor(B, C, H, W) - the original x\n",
    "        t: torch.Tensor(B) \\in [0, 1] - the time\n",
    "        Return the mean and variance of x(t) given x(0).\n",
    "        \"\"\"\n",
    "        exponent_integral = -0.5 * self.beta_0 * t - 0.25 * (self.beta_T - self.beta_0) * t**2\n",
    "        mean = x * torch.exp(exponent_integral)\n",
    "        std = torch.sqrt((1 - torch.exp(2 * exponent_integral)))\n",
    "        return mean, std\n",
    "    \n",
    "    def reverse_sde(self, model, x, t):\n",
    "        \"\"\"\n",
    "        x: torch.Tensor(B, C, H, W) \n",
    "        t: torch.Tensor(B) \\in [0, 1]\n",
    "        model: Score model\n",
    "        Return the drift and diffusion of the reverse SDE, as explained in the paper.\n",
    "        \"\"\"\n",
    "        drift, diffusion = self.sde(x, t)\n",
    "        return drift - diffusion ** 2 * model(x, t), diffusion\n",
    "    \n",
    "    def reverse_pf_ode(self, model, x, t):\n",
    "        \"\"\"\n",
    "        Return the drift of the reverse ODE using Probability Flow sampling.\n",
    "        \"\"\"\n",
    "        drift, diffusion = self.sde(x, t)\n",
    "        return drift - 0.5 * diffusion ** 2 * model(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDELoss(nn.Module):\n",
    "    def __init__(self, sde):\n",
    "        super().__init__()\n",
    "        self.sde = sde\n",
    "\n",
    "    def forward(self, model, x):\n",
    "        \"\"\"\n",
    "        model: Score model\n",
    "        x: torch.Tensor(B, C, H, W) - train data.\n",
    "        \"\"\"\n",
    "        t = torch.rand(x.shape[0], device=device)\n",
    "        noise = torch.randn_like(x)\n",
    "        mean, std = self.sde.dist(x, t)\n",
    "        x_t = mean + std * noise\n",
    "        score_prediction = model(x_t, t)\n",
    "        return F.mse_loss(score_prediction * std, -noise)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\n",
    "    \"state\": \"train\",\n",
    "    \"epoch\": 50,\n",
    "    \"batch_size\": 64,\n",
    "    \"T\": 1000,\n",
    "    \"channel\": 32,\n",
    "    \"channel_mult\": [1, 2],\n",
    "    \"attn\": [],\n",
    "    \"num_res_blocks\": 2,\n",
    "    \"dropout\": 0.15,\n",
    "    \"lr\": 5e-4,\n",
    "    \"multiplier\": 2.,\n",
    "    \"beta_1\": 1e-4,\n",
    "    \"beta_T\": 0.02,\n",
    "    \"img_size\": 28,\n",
    "    \"grad_clip\": 1.,\n",
    "    \"device\": \"cuda:0\",\n",
    "    \"training_load_weight\": None,\n",
    "    \"save_weight_dir\": \"./Checkpoints/\",\n",
    "    \"test_load_weight\": \"ckpt_49_.pt\",\n",
    "    \"sampled_dir\": \"\",\n",
    "    \"sampledNoisyImgName\": \"NoisyNoGuidenceImgs.png\",\n",
    "    \"sampledImgName\": \"SampledNoGuidenceImgs.png\",\n",
    "    \"nrow\": 8,\n",
    "    \"show_process\": True,\n",
    "    \"corrector_steps\": 2,\n",
    "    \"corrector_step_size\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model_config):\n",
    "    model = UNet(\n",
    "        T=model_config[\"T\"],\n",
    "        ch=model_config[\"channel\"],\n",
    "        ch_mult=model_config[\"channel_mult\"],\n",
    "        attn=model_config[\"attn\"],\n",
    "        num_res_blocks=model_config[\"num_res_blocks\"],\n",
    "        dropout=model_config[\"dropout\"]\n",
    "    ).to(model_config[\"device\"])\n",
    "\n",
    "    sde = VPSDE(model_config[\"beta_1\"], model_config[\"beta_T\"], model_config[\"T\"])\n",
    "    sde_loss = SDELoss(sde)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=model_config[\"lr\"])\n",
    "    model.train()\n",
    "\n",
    "    train_dataset = MNIST(\n",
    "        root=\"./data\", train=True, download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize(model_config[\"img_size\"]),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    )\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=model_config[\"batch_size\"], shuffle=True\n",
    "    )\n",
    "\n",
    "    if not os.path.exists(model_config[\"save_weight_dir\"]):\n",
    "        os.makedirs(model_config[\"save_weight_dir\"])\n",
    "\n",
    "    if model_config[\"training_load_weight\"]:\n",
    "        model.load_state_dict(torch.load(model_config[\"training_load_weight\"]))\n",
    "\n",
    "    for epoch in range(model_config[\"epoch\"]):\n",
    "        for x, _ in tqdm(train_loader):\n",
    "            x = x.to(model_config[\"device\"])\n",
    "            optimizer.zero_grad()\n",
    "            loss = sde_loss(model, x)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), model_config[\"grad_clip\"])\n",
    "            optimizer.step()\n",
    "        if model_config[\"show_process\"]:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "        torch.save(model.state_dict(), model_config[\"save_weight_dir\"] + f\"ckpt_{epoch}_.pt\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "\n",
    "class Predictor(abc.ABC):\n",
    "    def __init__(self, model, sde):\n",
    "        self.model = model\n",
    "        self.sde = sde\n",
    "\n",
    "    def predictor_step(self, prev_x, t):\n",
    "        pass\n",
    "\n",
    "\n",
    "class Corrector(abc.ABC):\n",
    "    def __init__(self, model, sde):\n",
    "        self.model = model\n",
    "        self.sde = sde\n",
    "\n",
    "    def corrector_step(self, prev_x, t):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseDiffusionPredictor(Predictor):\n",
    "    def __init__(self, model, sde):\n",
    "        super().__init__(model, sde)\n",
    "    \n",
    "    def predictor_step(self, prev_x, t):\n",
    "        drift, diffusion = self.sde.reverse_sde(self.model, prev_x, t)\n",
    "        return prev_x - drift + diffusion ** 2 * self.model(prev_x, t) + diffusion * torch.randn_like(prev_x).to(prev_x.device)\n",
    "        \n",
    "\n",
    "class LangevinDynamicsCorrector(Corrector):\n",
    "    \"\"\"\n",
    "    Based on Algorithm 5 in the paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, sde, corrector_step_size):\n",
    "        super().__init__(model, sde)\n",
    "        self.corrector_step_size = corrector_step_size\n",
    "    \n",
    "    def corrector_step(self, prev_x, t):\n",
    "        score = self.model(prev_x, t)\n",
    "        noise = torch.randn_like(prev_x).to(prev_x.device)\n",
    "        score_norm = torch.linalg.norm(score.reshape(score.shape[0], -1), dim=1)\n",
    "        noise_norm = torch.linalg.norm(noise.reshape(noise.shape[0], -1), dim=1)\n",
    "        step_size = 2 * self.sde.alpha[(t*self.sde.T).int()] * (self.corrector_step_size * noise_norm / score_norm) ** 2\n",
    "        return prev_x + step_size[:, None, None, None] * score + torch.sqrt(2 * step_size)[:, None, None, None] * noise\n",
    "    \n",
    "        \n",
    "\n",
    "def predictor_corrector_step(model_config, predictor, corrector, x, t):\n",
    "    \"\"\"\n",
    "    predictor: Predictor\n",
    "    corrector: Corrector\n",
    "    x: torch.Tensor(B, C, H, W)\n",
    "    t: torch.Tensor(B)\n",
    "    \"\"\"\n",
    "    x = predictor.predictor_step(x, t)\n",
    "    for _ in range(model_config['corrector_steps']):\n",
    "        x = corrector.corrector_step(x, t)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1., 1., 4., 1., 3.],\n",
      "          [1., 3., 3., 4., 3.],\n",
      "          [1., 4., 3., 4., 0.],\n",
      "          [4., 4., 0., 3., 4.]],\n",
      "\n",
      "         [[2., 1., 0., 2., 4.],\n",
      "          [4., 3., 4., 4., 0.],\n",
      "          [4., 4., 2., 1., 1.],\n",
      "          [0., 2., 0., 0., 3.]],\n",
      "\n",
      "         [[2., 4., 4., 3., 0.],\n",
      "          [3., 1., 1., 2., 3.],\n",
      "          [0., 0., 3., 3., 4.],\n",
      "          [2., 2., 1., 3., 1.]]],\n",
      "\n",
      "\n",
      "        [[[3., 4., 1., 1., 2.],\n",
      "          [4., 4., 4., 2., 1.],\n",
      "          [3., 0., 4., 2., 0.],\n",
      "          [1., 1., 0., 2., 1.]],\n",
      "\n",
      "         [[1., 4., 2., 3., 2.],\n",
      "          [3., 2., 1., 1., 4.],\n",
      "          [3., 1., 2., 1., 2.],\n",
      "          [0., 3., 3., 3., 0.]],\n",
      "\n",
      "         [[3., 1., 1., 0., 0.],\n",
      "          [4., 4., 1., 0., 4.],\n",
      "          [0., 3., 2., 0., 3.],\n",
      "          [3., 0., 2., 1., 0.]]]])\n",
      "tensor([[1., 1., 4., 1., 3., 1., 3., 3., 4., 3., 1., 4., 3., 4., 0., 4., 4., 0.,\n",
      "         3., 4., 2., 1., 0., 2., 4., 4., 3., 4., 4., 0., 4., 4., 2., 1., 1., 0.,\n",
      "         2., 0., 0., 3., 2., 4., 4., 3., 0., 3., 1., 1., 2., 3., 0., 0., 3., 3.,\n",
      "         4., 2., 2., 1., 3., 1.],\n",
      "        [3., 4., 1., 1., 2., 4., 4., 4., 2., 1., 3., 0., 4., 2., 0., 1., 1., 0.,\n",
      "         2., 1., 1., 4., 2., 3., 2., 3., 2., 1., 1., 4., 3., 1., 2., 1., 2., 0.,\n",
      "         3., 3., 3., 0., 3., 1., 1., 0., 0., 4., 4., 1., 0., 4., 0., 3., 2., 0.,\n",
      "         3., 3., 0., 2., 1., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([426.0000, 327.0000])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample(model_config):\n",
    "    model = UNet(\n",
    "    T=model_config[\"T\"],\n",
    "    ch=model_config[\"channel\"],\n",
    "    ch_mult=model_config[\"channel_mult\"],\n",
    "    attn=model_config[\"attn\"],\n",
    "    num_res_blocks=model_config[\"num_res_blocks\"],\n",
    "    dropout=model_config[\"dropout\"]\n",
    "    ).to(device)\n",
    "    \n",
    "    ckpt = torch.load(os.path.join(\n",
    "        model_config[\"save_weight_dir\"], model_config[\"test_load_weight\"]), map_location=device, weights_only=True)\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "\n",
    "    sde = VPSDE(model_config[\"beta_1\"], model_config[\"beta_T\"], model_config[\"T\"])\n",
    "    predictor = ReverseDiffusionPredictor(model, sde)\n",
    "    corrector = LangevinDynamicsCorrector(model, sde, model_config[\"corrector_step_size\"])\n",
    "\n",
    "    x = torch.randn(model_config[\"nrow\"] ** 2, 1, model_config[\"img_size\"], model_config[\"img_size\"]).to(device)\n",
    "    noisy_images = x.cpu()\n",
    "    for t in reversed(range(model_config[\"pc_steps\"])):\n",
    "        x = predictor_corrector_step(model_config, predictor, corrector, x, t)\n",
    "\n",
    "    sampled_images = x.cpu()\n",
    "    sampled_images = torch.clamp(sampled_images, 0, 1)\n",
    "    noisy_images = torch.clamp(noisy_images, 0, 1)\n",
    "\n",
    "    save_image(sampled_images, model_config[\"sampled_dir\"] + model_config[\"sampledImgName\"], nrow=model_config[\"nrow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new_zeros() missing 1 required positional arguments: \"size\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnormal_()\n",
      "\u001b[0;31mTypeError\u001b[0m: new_zeros() missing 1 required positional arguments: \"size\""
     ]
    }
   ],
   "source": [
    "def diffusion_sample(model_config):\n",
    "    model = UNet(\n",
    "        ch=model_config[\"channel\"],\n",
    "        ch_mult=model_config[\"channel_mult\"],\n",
    "        attn=model_config[\"attn\"],\n",
    "        num_res_blocks=model_config[\"num_res_blocks\"],\n",
    "        dropout=model_config[\"dropout\"]\n",
    "    ).to(device)\n",
    "    \n",
    "    ckpt = torch.load(os.path.join(\n",
    "        model_config[\"save_weight_dir\"], model_config[\"test_load_weight\"]), map_location=device, weights_only=True)\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "    sde = VPSDE(model_config[\"beta_1\"], model_config[\"beta_T\"], model_config[\"T\"])\n",
    "\n",
    "    x = torch.randn(model_config[\"nrow\"] ** 2, 1, model_config[\"img_size\"], model_config[\"img_size\"]).to(device)\n",
    "    noisy_images = x.cpu()\n",
    "    for time in reversed(range(model_config[\"T\"])):\n",
    "        t = time / model_config[\"T\"]\n",
    "        if t == 0:\n",
    "            eps = 0\n",
    "        else:\n",
    "            eps = torch.randn_like(x)\n",
    "        t = x.new_ones(x.shape[0], dtype=int) * t\n",
    "        noise_pred = -model(x, t) * sde.dist(x, t)[1]\n",
    "        mean = sde.coeff_prev_diffusion * x - sde.coeff_noise_diffusion * noise_pred\n",
    "        var = sde.beta[time]\n",
    "        x = mean + torch.sqrt(var) * eps\n",
    "\n",
    "    sampled_images = x.cpu()\n",
    "    sampled_images = torch.clamp(sampled_images, 0, 1)\n",
    "    save_image(sampled_images, model_config[\"sampled_dir\"] + model_config[\"sampledImgName\"], nrow=model_config[\"nrow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[1.0000e-04]]]])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
